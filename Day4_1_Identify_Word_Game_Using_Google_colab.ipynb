{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwoDdDPGMcZLAi0oTB1Ga2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meetAmarAtGithub/15_Reva_Speech_Analytics/blob/main/Day4_1_Identify_Word_Game_Using_Google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "# all imports\n",
        "#For Audio File\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "#For speech recognition\n",
        "import random\n",
        "import time\n",
        "import speech_recognition as sr\n",
        "\n",
        "#Javascript to record audio from microphone\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "def recognize_speech_from_audio_file(recognizer, audio_file):\n",
        "    \"\"\"\n",
        "    Transcribe speech from an audio file.\n",
        "\n",
        "    Returns a dictionary with three keys:\n",
        "    - \"success\": a boolean indicating whether or not the API request was successful\n",
        "    - \"error\": `None` if no error occurred, otherwise a string containing an error message if the API could not be reached or speech was unrecognizable\n",
        "    - \"transcription\": `None` if speech could not be transcribed, otherwise a string containing the transcribed text\n",
        "    \"\"\"\n",
        "    if not isinstance(recognizer, sr.Recognizer):\n",
        "        raise TypeError(\"`recognizer` must be a `Recognizer` instance\")\n",
        "\n",
        "    response = {\n",
        "        \"success\": True,\n",
        "        \"error\": None,\n",
        "        \"transcription\": None\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(audio_file) as source:\n",
        "            audio = recognizer.record(source)\n",
        "        response[\"transcription\"] = recognizer.recognize_google(audio)\n",
        "    except sr.RequestError:\n",
        "        response[\"success\"] = False\n",
        "        response[\"error\"] = \"API unavailable\"\n",
        "    except sr.UnknownValueError:\n",
        "        response[\"error\"] = \"Unable to recognize speech\"\n",
        "\n",
        "    return response\n",
        "\n",
        "#Record audio from Microphone\n",
        "'''\n",
        "One can't use the mic from Google Colab directly as we do with our own machine. One have to use JavaScript to let the browser enable the mic.\n",
        "'''\n",
        "def record(sec=3):\n",
        "  print(\"Speak Now...\")\n",
        "  display(Javascript(RECORD))\n",
        "  sec += 1\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  print(\"Done Recording !\")\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  return b #byte stream\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    WORDS = [\"apple\", \"banana\", \"grape\", \"orange\", \"mango\", \"lemon\"]\n",
        "    NUM_GUESSES = 3\n",
        "    PROMPT_LIMIT = 5\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    word = random.choice(WORDS)\n",
        "\n",
        "    instructions = (\n",
        "        \"I'm thinking of one of these words:\\n\"\n",
        "        \"{words}\\n\"\n",
        "        \"You have {n} tries to guess which one.\\n\"\n",
        "    ).format(words=', '.join(WORDS), n=NUM_GUESSES)\n",
        "\n",
        "    print(instructions)\n",
        "    time.sleep(3)\n",
        "\n",
        "    for i in range(NUM_GUESSES):\n",
        "        for j in range(PROMPT_LIMIT):\n",
        "            print('Guess {}. Provide the path to an audio file:'.format(i + 1))\n",
        "            audio_file = record(5)\n",
        "            guess = recognize_speech_from_audio_file(recognizer, audio_file)\n",
        "            if guess[\"transcription\"]:\n",
        "                break\n",
        "            if not guess[\"success\"]:\n",
        "                break\n",
        "            print(\"Unable to transcribe speech. Please try again.\")\n",
        "\n",
        "        if guess[\"error\"]:\n",
        "            print(\"ERROR: {}\".format(guess[\"error\"]))\n",
        "            break\n",
        "\n",
        "        print(\"You said: {}\".format(guess[\"transcription\"]))\n",
        "\n",
        "        guess_is_correct = guess[\"transcription\"].lower() == word.lower()\n",
        "        user_has_more_attempts = i < NUM_GUESSES - 1\n",
        "\n",
        "        if guess_is_correct:\n",
        "            print(\"Correct! You win!\".format(word))\n",
        "            break\n",
        "        elif user_has_more_attempts:\n",
        "            print(\"Incorrect. Try again.\\n\")\n",
        "        else:\n",
        "            print(\"Sorry, you lose!\\nI was thinking of '{}'.\".format(word))\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "p_2fo-jOPOPg",
        "outputId": "b017599c-3b7a-4bd9-e7b0-a825b70d927e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "I'm thinking of one of these words:\n",
            "apple, banana, grape, orange, mango, lemon\n",
            "You have 3 tries to guess which one.\n",
            "\n",
            "Guess 1. Provide the path to an audio file:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording !\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7a91c4510923>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Guess {}. Provide the path to an audio file:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognize_speech_from_audio_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecognizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcription\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-7a91c4510923>\u001b[0m in \u001b[0;36mrecognize_speech_from_audio_file\u001b[0;34m(recognizer, audio_file)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcription\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename_or_fileobject)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_fileobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Given audio file must be a filename string or a file-like object\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename_or_fileobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Given audio file must be a filename string or a file-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IRnZSC9PPZs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd \"/content/gdrive/My Drive/Colab Notebooks/Reva/15_Speech_Analytics\"\n",
        "\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "# all imports\n",
        "import random\n",
        "import time\n",
        "import speech_recognition as sr\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "import wave\n",
        "\n",
        "# Set the path to your Google Drive folder\n",
        "AUDIO_SAVE_PATH = \"/content/gdrive/My Drive/Colab Notebooks/Reva/15_Speech_Analytics\"\n",
        "\n",
        "# Javascript to record audio from microphone\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def recognize_speech_from_audio_file(recognizer, audio_file):\n",
        "    \"\"\"\n",
        "    Transcribe speech from an audio file.\n",
        "\n",
        "    Returns a dictionary with three keys:\n",
        "    - \"success\": a boolean indicating whether or not the API request was successful\n",
        "    - \"error\": `None` if no error occurred, otherwise a string containing an error message if the API could not be reached or speech was unrecognizable\n",
        "    - \"transcription\": `None` if speech could not be transcribed, otherwise a string containing the transcribed text\n",
        "    \"\"\"\n",
        "    if not isinstance(recognizer, sr.Recognizer):\n",
        "        raise TypeError(\"`recognizer` must be a `Recognizer` instance\")\n",
        "\n",
        "    response = {\n",
        "        \"success\": True,\n",
        "        \"error\": None,\n",
        "        \"transcription\": None\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(audio_file) as source:\n",
        "            audio = recognizer.record(source)\n",
        "        response[\"transcription\"] = recognizer.recognize_google(audio)\n",
        "    except sr.RequestError:\n",
        "        response[\"success\"] = False\n",
        "        response[\"error\"] = \"API unavailable\"\n",
        "    except sr.UnknownValueError:\n",
        "        response[\"error\"] = \"Unable to recognize speech\"\n",
        "\n",
        "    return response\n",
        "\n",
        "# Record audio from Microphone\n",
        "def record(sec=3):\n",
        "    print(\"Speak Now...\")\n",
        "    display(Javascript(RECORD))\n",
        "    sec += 1\n",
        "    s = output.eval_js('record(%d)' % (sec*1000))\n",
        "    print(\"Done Recording !\")\n",
        "    b = b64decode(s.split(',')[1])\n",
        "\n",
        "    # Save the audio file to Google Drive\n",
        "    audio_file_path = AUDIO_SAVE_PATH + \"audio.wav\"\n",
        "    with wave.open(audio_file_path, \"wb\") as f:\n",
        "        f.setnchannels(1)  # Set the number of channels (mono)\n",
        "        f.setsampwidth(2)  # Set the sample width (16-bit)\n",
        "        f.setframerate(16000)  # Set the sample rate (16 kHz)\n",
        "        f.writeframes(b)\n",
        "\n",
        "    return audio_file_path\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    WORDS = [\"apple\", \"banana\", \"grape\", \"orange\", \"mango\", \"lemon\"]\n",
        "    NUM_GUESSES = 3\n",
        "    PROMPT_LIMIT = 5\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    word = random.choice(WORDS)\n",
        "\n",
        "    instructions = (\n",
        "        \"I'm thinking of one of these words:\\n\"\n",
        "        \"{words}\\n\"\n",
        "        \"You have {n} tries to guess which one.\\n\"\n",
        "    ).format(words=', '.join(WORDS), n=NUM_GUESSES)\n",
        "\n",
        "    print(instructions)\n",
        "    time.sleep(3)\n",
        "\n",
        "    for i in range(NUM_GUESSES):\n",
        "        for j in range(PROMPT_LIMIT):\n",
        "            print('Guess {}. Speak now:'.format(i + 1))\n",
        "            audio_file = record(5)\n",
        "            guess = recognize_speech_from_audio_file(recognizer, audio_file)\n",
        "            if guess[\"transcription\"]:\n",
        "                break\n",
        "            if not guess[\"success\"]:\n",
        "                break\n",
        "            print(\"Unable to transcribe speech. Please try again.\")\n",
        "\n",
        "        if guess[\"error\"]:\n",
        "            print(\"ERROR: {}\".format(guess[\"error\"]))\n",
        "            break\n",
        "\n",
        "        print(\"You said: {}\".format(guess[\"transcription\"]))\n",
        "\n",
        "        guess_is_correct = guess[\"transcription\"].lower() == word.lower()\n",
        "        user_has_more_attempts = i < NUM_GUESSES - 1\n",
        "\n",
        "        if guess_is_correct:\n",
        "            print(\"Correct! You win!\")\n",
        "            break\n",
        "        elif user_has_more_attempts:\n",
        "            print(\"Incorrect. Try again.\\n\")\n",
        "        else:\n",
        "            print(\"Sorry, you lose!\\nI was thinking of '{}'.\".format(word))\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "jtj9FlxZVAI3",
        "outputId": "d6e9287b-294b-4078-bd7f-1306e75a4ce6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/Reva/15_Speech_Analytics\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "I'm thinking of one of these words:\n",
            "apple, banana, grape, orange, mango, lemon\n",
            "You have 3 tries to guess which one.\n",
            "\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording !\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording !\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording !\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording !\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording !\n",
            "Unable to transcribe speech. Please try again.\n",
            "ERROR: Unable to recognize speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lrp5gAA1VARt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import random\n",
        "import time\n",
        "import speech_recognition as sr\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record_audio(duration):\n",
        "    \"\"\"\n",
        "    Record audio for the specified duration (in seconds) and return the audio data in byte format.\n",
        "    \"\"\"\n",
        "    print(\"Speak Now...\")\n",
        "    display(Javascript(RECORD))\n",
        "    sec = int(duration) + 1\n",
        "    s = output.eval_js('record(%d)' % (sec * 1000))\n",
        "    print(\"Done Recording!\")\n",
        "\n",
        "    try:\n",
        "        audio_bytes = b64decode(s.split(',')[1])\n",
        "        return audio_bytes\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred while decoding the audio: {}\".format(e))\n",
        "        return None\n",
        "\n",
        "\n",
        "def recognize_speech_from_audio_byte(recognizer, audio_byte):\n",
        "    \"\"\"\n",
        "    Transcribe speech from audio data in byte format.\n",
        "\n",
        "    Returns a dictionary with three keys:\n",
        "    - \"success\": a boolean indicating whether or not the API request was successful\n",
        "    - \"error\": `None` if no error occurred, otherwise a string containing an error message if the API could not be reached or speech was unrecognizable\n",
        "    - \"transcription\": `None` if speech could not be transcribed, otherwise a string containing the transcribed text\n",
        "    \"\"\"\n",
        "    if not isinstance(recognizer, sr.Recognizer):\n",
        "        raise TypeError(\"`recognizer` must be a `Recognizer` instance\")\n",
        "\n",
        "    response = {\n",
        "        \"success\": True,\n",
        "        \"error\": None,\n",
        "        \"transcription\": None\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        audio = sr.AudioData(audio_byte, sample_rate=16000, sample_width=2)  # Modify the sample_rate and sample_width if necessary\n",
        "        response[\"transcription\"] = recognizer.recognize_google(audio)\n",
        "    except sr.RequestError as e:\n",
        "        response[\"success\"] = False\n",
        "        response[\"error\"] = \"API request error: {}\".format(e)\n",
        "    except sr.UnknownValueError:\n",
        "        response[\"error\"] = \"Speech could not be transcribed\"\n",
        "    except Exception as e:\n",
        "        response[\"error\"] = \"An error occurred: {}\".format(e)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    WORDS = [\"apple\", \"banana\", \"grape\", \"orange\", \"mango\", \"lemon\"]\n",
        "    NUM_GUESSES = 3\n",
        "    PROMPT_LIMIT = 5\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    word = random.choice(WORDS)\n",
        "\n",
        "    instructions = (\n",
        "        \"I'm thinking of one of these words:\\n\"\n",
        "        \"{words}\\n\"\n",
        "        \"You have {n} tries to guess which one.\\n\"\n",
        "    ).format(words=', '.join(WORDS), n=NUM_GUESSES)\n",
        "\n",
        "    print(instructions)\n",
        "    time.sleep(3)\n",
        "\n",
        "    for i in range(NUM_GUESSES):\n",
        "        for j in range(PROMPT_LIMIT):\n",
        "            print('Guess {}. Speak now:'.format(i + 1))\n",
        "            audio_byte = record_audio(2)  # Record audio in byte format\n",
        "            guess = recognize_speech_from_audio_byte(recognizer, audio_byte)\n",
        "            if guess[\"transcription\"]:\n",
        "                break\n",
        "            if not guess[\"success\"]:\n",
        "                break\n",
        "            print(\"Unable to transcribe speech. Please try again.\")\n",
        "\n",
        "        if guess[\"error\"]:\n",
        "            print(\"ERROR: {}\".format(guess[\"error\"]))\n",
        "            break\n",
        "\n",
        "        print(\"You said: {}\".format(guess[\"transcription\"]))\n",
        "\n",
        "        guess_is_correct = guess[\"transcription\"].lower() == word.lower()\n",
        "        user_has_more_attempts = i < NUM_GUESSES - 1\n",
        "\n",
        "        if guess_is_correct:\n",
        "            print(\"Correct! You win!\".format(word))\n",
        "            break\n",
        "        elif user_has_more_attempts:\n",
        "            print(\"Incorrect. Try again.\\n\")\n",
        "        else:\n",
        "            print(\"Sorry, you lose!\\nI was thinking of '{}'.\".format(word))\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "hYbsd6aWVAXN",
        "outputId": "406e3305-d9df-4f1b-f23c-8aa471ddf310"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "I'm thinking of one of these words:\n",
            "apple, banana, grape, orange, mango, lemon\n",
            "You have 3 tries to guess which one.\n",
            "\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "Unable to transcribe speech. Please try again.\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "Unable to transcribe speech. Please try again.\n",
            "ERROR: Speech could not be transcribed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSbZg03Gamvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk\n",
        "\n",
        "import random\n",
        "import time\n",
        "import vosk\n",
        "import sys\n",
        "import os\n",
        "import wave\n",
        "\n",
        "def recognize_speech_from_audio_byte(recognizer, audio_byte):\n",
        "    \"\"\"\n",
        "    Transcribe speech from audio data in byte format using the Vosk library.\n",
        "\n",
        "    Returns a dictionary with three keys:\n",
        "    - \"success\": a boolean indicating whether or not the speech recognition was successful\n",
        "    - \"error\": `None` if no error occurred, otherwise a string containing an error message if the recognition failed\n",
        "    - \"transcription\": `None` if speech could not be transcribed, otherwise a string containing the transcribed text\n",
        "    \"\"\"\n",
        "    if not isinstance(recognizer, vosk.KaldiRecognizer):\n",
        "        raise TypeError(\"`recognizer` must be a `vosk.KaldiRecognizer` instance\")\n",
        "\n",
        "    response = {\n",
        "        \"success\": True,\n",
        "        \"error\": None,\n",
        "        \"transcription\": None\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        recognizer.AcceptWaveform(audio_byte)\n",
        "        response[\"transcription\"] = recognizer.Result()\n",
        "    except Exception as e:\n",
        "        response[\"success\"] = False\n",
        "        response[\"error\"] = \"Speech recognition failed: {}\".format(e)\n",
        "\n",
        "    return response\n",
        "\n",
        "def record_audio(duration):\n",
        "    \"\"\"\n",
        "    Record audio for the specified duration (in seconds) and return the audio data in byte format.\n",
        "    \"\"\"\n",
        "    print(\"Speak Now...\")\n",
        "    display(Javascript(RECORD))\n",
        "    sec = int(duration) + 1\n",
        "    s = output.eval_js('record(%d)' % (sec * 1000))\n",
        "    print(\"Done Recording!\")\n",
        "\n",
        "    try:\n",
        "        audio_bytes = b64decode(s.split(',')[1])\n",
        "        return audio_bytes\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred while decoding the audio: {}\".format(e))\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the list of words, maximum number of guesses, and prompt limit\n",
        "    WORDS = [\"apple\", \"banana\", \"grape\", \"orange\", \"mango\", \"lemon\"]\n",
        "    NUM_GUESSES = 3\n",
        "    PROMPT_LIMIT = 5\n",
        "\n",
        "    # Download and extract the Vosk model\n",
        "    !wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "    !unzip vosk-model-small-en-us-0.15.zip\n",
        "\n",
        "    # Create a Vosk recognizer instance\n",
        "    model_path = \"vosk-model-small-en-us-0.15\"\n",
        "    if not os.path.exists(model_path):\n",
        "        sys.stderr.write(f'Model folder not found in {model_path}.')\n",
        "        sys.exit(1)\n",
        "    model = vosk.Model(model_path)\n",
        "    sample_rate = 16000\n",
        "    recognizer = vosk.KaldiRecognizer(model, sample_rate)\n",
        "\n",
        "    # Get a random word from the list\n",
        "    word = random.choice(WORDS)\n",
        "\n",
        "    # Format the instructions string\n",
        "    instructions = (\n",
        "        \"I'm thinking of one of these words:\\n\"\n",
        "        \"{words}\\n\"\n",
        "        \"You have {n} tries to guess which one.\\n\"\n",
        "    ).format(words=', '.join(WORDS), n=NUM_GUESSES)\n",
        "\n",
        "    # Show instructions and wait 3 seconds before starting the game\n",
        "    print(instructions)\n",
        "    time.sleep(3)\n",
        "\n",
        "    for i in range(NUM_GUESSES):\n",
        "        for j in range(PROMPT_LIMIT):\n",
        "            print('Guess {}. Speak now:'.format(i + 1))\n",
        "            audio_byte = record_audio(5)  # Record audio in byte format\n",
        "            guess = recognize_speech_from_audio_byte(recognizer, audio_byte)\n",
        "            if guess[\"transcription\"]:\n",
        "                break\n",
        "\n",
        "        if guess[\"error\"]:\n",
        "            print(\"ERROR: {}\".format(guess[\"error\"]))\n",
        "            break\n",
        "\n",
        "        print(\"You said: {}\".format(guess[\"transcription\"]))\n",
        "\n",
        "        guess_is_correct = guess[\"transcription\"].strip().lower() == word.lower()\n",
        "        user_has_more_attempts = i < NUM_GUESSES - 1\n",
        "\n",
        "        if guess_is_correct:\n",
        "            print(\"Correct! You win!\")\n",
        "            break\n",
        "        elif user_has_more_attempts:\n",
        "            print(\"Incorrect. Try again.\")\n",
        "        else:\n",
        "            print(\"Sorry, you're out of guesses. The word was '{}'\".format(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bQGyVYwUam3W",
        "outputId": "7e6d3c1b-050d-4f15-e5d9-a669802da7d1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vosk in /usr/local/lib/python3.10/dist-packages (0.3.45)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.15.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.65.0)\n",
            "Requirement already satisfied: srt in /usr/local/lib/python3.10/dist-packages (from vosk) (3.5.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from vosk) (11.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4)\n",
            "--2023-06-17 03:36:40--  https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41205931 (39M) [application/zip]\n",
            "Saving to: vosk-model-small-en-us-0.15.zip.1\n",
            "\n",
            "vosk-model-small-en 100%[===================>]  39.30M  19.6MB/s    in 2.0s    \n",
            "\n",
            "2023-06-17 03:36:43 (19.6 MB/s) - vosk-model-small-en-us-0.15.zip.1 saved [41205931/41205931]\n",
            "\n",
            "Archive:  vosk-model-small-en-us-0.15.zip\n",
            "replace vosk-model-small-en-us-0.15/am/final.mdl? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/am/final.mdl  \n",
            "replace vosk-model-small-en-us-0.15/graph/disambig_tid.int? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/graph/disambig_tid.int  \n",
            "replace vosk-model-small-en-us-0.15/graph/HCLr.fst? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/graph/HCLr.fst  \n",
            "replace vosk-model-small-en-us-0.15/graph/Gr.fst? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/graph/Gr.fst  \n",
            "replace vosk-model-small-en-us-0.15/graph/phones/word_boundary.int? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/graph/phones/word_boundary.int  \n",
            "replace vosk-model-small-en-us-0.15/conf/model.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/conf/model.conf  \n",
            "replace vosk-model-small-en-us-0.15/conf/mfcc.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/conf/mfcc.conf  \n",
            "replace vosk-model-small-en-us-0.15/ivector/splice.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/splice.conf  \n",
            "replace vosk-model-small-en-us-0.15/ivector/final.dubm? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/final.dubm  \n",
            "replace vosk-model-small-en-us-0.15/ivector/global_cmvn.stats? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/global_cmvn.stats  \n",
            "replace vosk-model-small-en-us-0.15/ivector/final.ie? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/final.ie  \n",
            "replace vosk-model-small-en-us-0.15/ivector/online_cmvn.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/online_cmvn.conf  \n",
            "replace vosk-model-small-en-us-0.15/ivector/final.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace vosk-model-small-en-us-0.15/ivector/final.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/ivector/final.mat  \n",
            "replace vosk-model-small-en-us-0.15/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vosk-model-small-en-us-0.15/README  \n",
            "I'm thinking of one of these words:\n",
            "apple, banana, grape, orange, mango, lemon\n",
            "You have 3 tries to guess which one.\n",
            "\n",
            "Guess 1. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "You said: {\n",
            "  \"text\" : \"\"\n",
            "}\n",
            "Incorrect. Try again.\n",
            "Guess 2. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "You said: {\n",
            "  \"text\" : \"\"\n",
            "}\n",
            "Incorrect. Try again.\n",
            "Guess 3. Speak now:\n",
            "Speak Now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Recording!\n",
            "You said: {\n",
            "  \"text\" : \"\"\n",
            "}\n",
            "Sorry, you're out of guesses. The word was 'orange'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0HFgSRpa45l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}